"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[4764],{4106:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>h,frontMatter:()=>d,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"getting-started/advanced-deployment-options/docker","title":"Start a node with Docker","description":"You can run all the commands in this document without any change on any machine with the latest Docker and at least 8GB of RAM available to the container.","source":"@site/docs/getting-started/advanced-deployment-options/docker.md","sourceDirName":"getting-started/advanced-deployment-options","slug":"/getting-started/advanced-deployment-options/docker","permalink":"/getting-started/advanced-deployment-options/docker","draft":false,"unlisted":false,"editUrl":"https://github.com/GaiaNet-AI/docs/edit/main/docs/getting-started/advanced-deployment-options/docker.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1},"sidebar":"tutorialSidebar","previous":{"title":"Advanced Deployment Options","permalink":"/category/advanced-deployment-options"},"next":{"title":"Start a node on AWS using AMI images","permalink":"/getting-started/advanced-deployment-options/aws"}}');var a=t(4848),i=t(8453);const d={sidebar_position:1},r="Start a node with Docker",s={},c=[{value:"Quick start",id:"quick-start",level:2},{value:"Stop and re-start",id:"stop-and-re-start",level:2},{value:"Make changes to the node",id:"make-changes-to-the-node",level:2},{value:"Change the node ID",id:"change-the-node-id",level:2},{value:"Build a node image locally",id:"build-a-node-image-locally",level:2}];function l(e){const n={a:"a",blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"start-a-node-with-docker",children:"Start a node with Docker"})}),"\n",(0,a.jsx)(n.p,{children:"You can run all the commands in this document without any change on any machine with the latest Docker and at least 8GB of RAM available to the container.\nBy default, the container uses the CPU to perform computations, which could be slow for large LLMs. For GPUs,"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Mac: Everything here works on ",(0,a.jsx)(n.a,{href:"https://docs.docker.com/desktop/install/mac-install/",children:"Docker Desktop for Mac"}),". However, the Apple GPU cores will not be available inside Docker containers until ",(0,a.jsx)(n.a,{href:"https://github.com/LlamaEdge/LlamaEdge/blob/main/docker/webgpu.md",children:"WebGPU is supported by Docker"})," later in 2024."]}),"\n",(0,a.jsxs)(n.li,{children:["Windows and Linux with Nvidia GPU: You will need to install ",(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation",children:"NVIDIA Container Toolkit"})," for Docker. In the instructions below, replace the ",(0,a.jsx)(n.code,{children:"latest"})," tag with ",(0,a.jsx)(n.code,{children:"cuda12"})," or ",(0,a.jsx)(n.code,{children:"cuda11"})," to use take advantage of the GPU, and add the ",(0,a.jsx)(n.code,{children:"--device nvidia.com/gpu=all"})," flag. If you need to build the images yourself, replace ",(0,a.jsx)(n.code,{children:"Dockerfile"})," with ",(0,a.jsx)(n.code,{children:"Dockerfile.cuda12"})," or ",(0,a.jsx)(n.code,{children:"Dockerfile.cuda11"}),"."]}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Find ",(0,a.jsx)(n.a,{href:"https://hub.docker.com/?namespace=gaianet",children:"Gaia Docker images"})," you can run!"]}),"\n",(0,a.jsx)(n.h2,{id:"quick-start",children:"Quick start"}),"\n",(0,a.jsx)(n.p,{children:"Start a Docker container for the Gaia node. It will print running logs from the Gaia node in this terminal."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker run --name gaianet \\\n  -p 8080:8080 \\\n  -v $(pwd)/qdrant_storage:/root/gaianet/qdrant/storage:z \\\n  gaianet/phi-3-mini-instruct-4k_paris:latest\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The node is ready when it shows ",(0,a.jsx)(n.code,{children:"The Gaia node is started at: https://..."})," on the console.\nYou can go to that URL from your browser to interact with the Gaia node."]}),"\n",(0,a.jsxs)(n.p,{children:["The docker image contains the LLM and embedding models required by the node. However, the vector\ncollection snapshot (i.e., knowledge base) is downloaded and imported at the time when the node\nstarts up. That is because the knowledge based could be updated frequently. The ",(0,a.jsx)(n.code,{children:"qdrant_storage"}),"\ndirectory on the host machine stores the vector database content."]}),"\n",(0,a.jsx)(n.p,{children:"Alternatively, the command to run the Gaia on your Nvidia CUDA 12 machine is as follows."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker run --name gaianet \\\n  -p 8080:8080 --device nvidia.com/gpu=all \\\n  -v $(pwd)/qdrant_storage:/root/gaianet/qdrant/storage:z \\\n  gaianet/phi-3-mini-instruct-4k_paris:cuda12\n"})}),"\n",(0,a.jsx)(n.h2,{id:"stop-and-re-start",children:"Stop and re-start"}),"\n",(0,a.jsx)(n.p,{children:"You can stop and re-start the node as follows. Every time you re-start, it will re-initailize the vector\ncollection (knowledge base)."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker stop gaianet\ndocker start gaianet\n"})}),"\n",(0,a.jsx)(n.p,{children:"NOTE: When you restart the node, the log messages will no longer be printed to the console.\nYou will need to wait for a few minutes before the restarted node comes back online. You can still see\nthe logs by logging into the container as follows."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker exec -it gaianet /bin/bash\ntail -f /root/gaianet/log/start-llamaedge.log\n"})}),"\n",(0,a.jsx)(n.p,{children:"You can also delete the node if you no longer needs it."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker stop gaianet\ndocker rm gaianet\n"})}),"\n",(0,a.jsx)(n.h2,{id:"make-changes-to-the-node",children:"Make changes to the node"}),"\n",(0,a.jsxs)(n.p,{children:["You can update the configuration parameters of the node, such as context size for the models, by\nexecuting the ",(0,a.jsx)(n.code,{children:"config"})," command on the ",(0,a.jsx)(n.code,{children:"gaianet"})," program inside the container.\nFor example, the following command changes the chat LLM's context size to 8192 tokens."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker exec -it gaianet /root/gaianet/bin/gaianet config --chat-ctx-size 8192\n"})}),"\n",(0,a.jsx)(n.p,{children:"Then, restart the node for the new configuration to take effect.\nYou will need to wait for a few minutes for the server to start again, or you can monitor\nthe log files inside the container as discussed above."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker stop gaianet\ndocker start gaianet\n"})}),"\n",(0,a.jsx)(n.h2,{id:"change-the-node-id",children:"Change the node ID"}),"\n",(0,a.jsxs)(n.p,{children:["You can update the node ID (Ethereum address) associated with the node. Start the node and copy the ",(0,a.jsx)(n.code,{children:"nodeid.json"}),"\nfile, as well as the keystore file defined in ",(0,a.jsx)(n.code,{children:"nodeid.json"})," into the container."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker cp /local/path/to/nodeid.json gaianet:/root/gaianet/nodeid.json\ndocker cp /local/path/to/1234-abcd-key-store gaianet:/root/gaianet/1234-abcd-key-store\n"})}),"\n",(0,a.jsx)(n.p,{children:"THen, restart the node for the new address and keystore to take effect."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker stop gaianet\ndocker start gaianet\n"})}),"\n",(0,a.jsx)(n.h2,{id:"build-a-node-image-locally",children:"Build a node image locally"}),"\n",(0,a.jsxs)(n.p,{children:["Each Gaia is defined by a ",(0,a.jsx)(n.code,{children:"config.json"})," file. It defines the node's required\nLLM and embedding models, model parameters,\nprompts, and vector snapshots (e.g., knowledge base).\nThe following command builds a Docker image with two platforms\nfor a node based on the specified ",(0,a.jsx)(n.code,{children:"config.json"})," file."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker buildx build . --platform linux/arm64,linux/amd64 \\\n  --tag gaianet/phi-3-mini-instruct-4k_paris:latest -f Dockerfile \\\n  --build-arg CONFIG_URL=https://raw.githubusercontent.com/GaiaNet-AI/gaianet-node/main/config.json\n"})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.code,{children:"Dockerfile"})," is available ",(0,a.jsx)(n.a,{href:"https://raw.githubusercontent.com/GaiaNet-AI/gaianet-node/main/docker/Dockerfile",children:"here"}),". Feel free to change it to Nvidia ",(0,a.jsx)(n.a,{href:"https://raw.githubusercontent.com/GaiaNet-AI/gaianet-node/main/docker/Dockerfile.cuda12",children:"CUDA versions"})," if your Docker is enabled with the ",(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html",children:"Nvidia container toolkit"}),"."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"You can publish your node for other people to use it."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"docker push gaianet/phi-3-mini-instruct-4k_paris:latest\n"})})]})}function h(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>d,x:()=>r});var o=t(6540);const a={},i=o.createContext(a);function d(e){const n=o.useContext(i);return o.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:d(e.components),o.createElement(i.Provider,{value:n},e.children)}}}]);