"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[7971],{8521:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>h,frontMatter:()=>r,metadata:()=>s,toc:()=>o});const s=JSON.parse('{"id":"user-guide/apps/llamaparse","title":"LlamaCloud","description":"LlamaParse is an API created by LlamaIndex to efficiently parse and represent files for efficient retrieval and context augmentation using LlamaIndex frameworks. LlamaParse can support different kinds of files, like pdf, doc, .ppt, and other formats.","source":"@site/versioned_docs/version-1.0.0/user-guide/apps/llamaparse.md","sourceDirName":"user-guide/apps","slug":"/user-guide/apps/llamaparse","permalink":"/1.0.0/user-guide/apps/llamaparse","draft":false,"unlisted":false,"editUrl":"https://github.com/GaiaNet-AI/docs/edit/main/versioned_docs/version-1.0.0/user-guide/apps/llamaparse.md","tags":[],"version":"1.0.0","sidebarPosition":8,"frontMatter":{"sidebar_position":8},"sidebar":"tutorialSidebar","previous":{"title":"LobeChat","permalink":"/1.0.0/user-guide/apps/lobechat"},"next":{"title":"Zed","permalink":"/1.0.0/user-guide/apps/zed"}}');var i=t(4848),a=t(8453);const r={sidebar_position:8},d="LlamaCloud",l={},o=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Steps",id:"steps",level:2}];function c(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",header:"header",img:"img",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"llamacloud",children:"LlamaCloud"})}),"\n",(0,i.jsx)(n.p,{children:"LlamaParse is an API created by LlamaIndex to efficiently parse and represent files for efficient retrieval and context augmentation using LlamaIndex frameworks. LlamaParse can support different kinds of files, like pdf, doc, .ppt, and other formats."}),"\n",(0,i.jsx)(n.p,{children:"You can configure LlamaParse to use the GaiaNet node as the LLM backend, hence you can create a RAG application based on your PDF files locally."}),"\n",(0,i.jsx)(n.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,i.jsx)(n.p,{children:"You will need a Gaia node ready to provide LLM services through a public URL. You can"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/1.0.0/node-guide/quick-start",children:"run your own node"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"/1.0.0/user-guide/nodes",children:"use a public node"})}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"In this tutorial, we will use public nodes to power the Continue plugin."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Model type"}),(0,i.jsx)(n.th,{children:"API base URL"}),(0,i.jsx)(n.th,{children:"Model name"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Chat"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.a,{href:"https://gemma.us.gaianet.network/v1",children:"https://gemma.us.gaianet.network/v1"})}),(0,i.jsx)(n.td,{children:"gemma"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Embedding"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.a,{href:"https://gemma.us.gaianet.network/v1",children:"https://gemma.us.gaianet.network/v1"})}),(0,i.jsx)(n.td,{children:"nomic-embed"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"steps",children:"Steps"}),"\n",(0,i.jsxs)(n.p,{children:["We will use an open-sourced GitHub repo, called ",(0,i.jsx)(n.code,{children:"llamaparse-integration"}),",  to make LlamaPase easy to use.  The ",(0,i.jsx)(n.code,{children:"llamaparse-integration"})," application supports"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Multiple file formats, like ",(0,i.jsx)(n.code,{children:".pdf"})," and ",(0,i.jsx)(n.code,{children:".doc"}),","]}),"\n",(0,i.jsx)(n.li,{children:"Multiple files"}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"We will need to get the source code in your terminal first."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"git clone https://github.com/alabulei1/llamaparse-integration.git\ncd llamaparse-integration\n"})}),"\n",(0,i.jsx)(n.p,{children:"Next, install the required mode packages."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"npm install llamaindex\nnpm install dotenv\n"})}),"\n",(0,i.jsx)(n.p,{children:"Start a Qdant instance. The Qdrant instance is to store the embeddings."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"mkdir qdrant_storage\nmkdir qdrant_snapshots\n\nnohup docker run -d -p 6333:6333 -p 6334:6334 \\\n    -v $(pwd)/qdrant_storage:/qdrant/storage:z \\\n    -v $(pwd)/qdrant_snapshots:/qdrant/snapshots:z \\\n    qdrant/qdrant\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Then, we will need to set up the LLM  model settings. We can configure the model setting in the ",(0,i.jsx)(n.code,{children:".env"})," file."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"OPENAI_BASE_URL=https://gemma.us.gaianet.network/v1/\nOPENAI_API_KEY=gaianet\nLLAMAEDGE_CHAT_MODEL=gemma\nLLAMAEDGE_EMBEDDING_MODEL=nomic\nLLAMA_CLOUD_API_KEY=Your_Own_KEY\nFILE_PATH=\nFILE_DIR=./pdf_dir\nCOLLECTION_NAME=default\nQDRANT_URL=http://127.0.0.1:6333\nSAVE_MARKDOWN_PATH=output.md\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Here are some notes about the ",(0,i.jsx)(n.code,{children:".env"})," setting:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["You can get the LlamaCloud key from ",(0,i.jsx)(n.a,{href:"https://cloud.llamaindex.ai",children:"https://cloud.llamaindex.ai"})]}),"\n",(0,i.jsx)(n.li,{children:"You may need to make changes according to your model setting and file path."}),"\n",(0,i.jsxs)(n.li,{children:["If you put your file name in the ",(0,i.jsx)(n.code,{children:"FILE_PATH="}),", the program will build a RAG application with this single pdf file."]}),"\n",(0,i.jsxs)(n.li,{children:["If the ",(0,i.jsx)(n.code,{children:"FILE_PATH="})," is empty, the program will build a RAG application with the files under the ",(0,i.jsx)(n.code,{children:"FILE_DIR=./pdf_dir"}),". You can include multiple files in the folder."]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:"Next, we can run the program to build an RAG application based on the PDF file"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"npx tsx pdfRender.ts\n"})}),"\n",(0,i.jsx)(n.p,{children:"After it runs successfully, you can send a query via the command line."}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:t(7296).A+"",width:"2918",height:"1620"})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},7296:(e,n,t)=>{t.d(n,{A:()=>s});const s=t.p+"assets/images/llamaparse-01-07933ece762716a4ea93c06f31abb0d5.png"},8453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>d});var s=t(6540);const i={},a=s.createContext(i);function r(e){const n=s.useContext(a);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),s.createElement(a.Provider,{value:n},e.children)}}}]);