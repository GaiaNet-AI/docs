"use strict";(self.webpackChunkdocs=self.webpackChunkdocs||[]).push([[1960],{6025:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"agent-integrations/flowiseai","title":"FlowiseAI RAG chat","description":"FlowiseAI is a low-code tool for developers to build customized LLM orchestration flows & AI agents. You can configure the FlowiseAI tool to use Gaia nodes as LLM service providers.","source":"@site/docs/agent-integrations/flowiseai.md","sourceDirName":"agent-integrations","slug":"/agent-integrations/flowiseai","permalink":"/agent-integrations/flowiseai","draft":false,"unlisted":false,"editUrl":"https://github.com/GaiaNet-AI/docs/edit/main/docs/agent-integrations/flowiseai.md","tags":[],"version":"current","sidebarPosition":5,"frontMatter":{"sidebar_position":5},"sidebar":"tutorialSidebar","previous":{"title":"Stockbot","permalink":"/agent-integrations/stockbot"},"next":{"title":"FlowiseAI tool call","permalink":"/agent-integrations/flowiseai-tool-call"}}');var o=n(4848),i=n(8453);const l={sidebar_position:5},a="FlowiseAI RAG chat",d={},c=[{value:"Prerequisites",id:"prerequisites",level:2},{value:"Start a FlowiseAI server",id:"start-a-flowiseai-server",level:2},{value:"Build a documents QnA chatbot",id:"build-a-documents-qna-chatbot",level:2},{value:"Get the <strong>Flowise Docs QnA</strong> template",id:"get-the-flowise-docs-qna-template",level:3},{value:"Connect the chat model API",id:"connect-the-chat-model-api",level:3},{value:"Connect the embedding model API",id:"connect-the-embedding-model-api",level:3},{value:"Set up your documents",id:"set-up-your-documents",level:3},{value:"Give it a try",id:"give-it-a-try",level:2},{value:"More examples",id:"more-examples",level:2}];function r(e){const t={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(t.header,{children:(0,o.jsx)(t.h1,{id:"flowiseai-rag-chat",children:"FlowiseAI RAG chat"})}),"\n",(0,o.jsx)(t.p,{children:"FlowiseAI is a low-code tool for developers to build customized LLM orchestration flows & AI agents. You can configure the FlowiseAI tool to use Gaia nodes as LLM service providers."}),"\n",(0,o.jsx)(t.h2,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,o.jsx)(t.p,{children:"You will need a Gaia node ready to provide LLM services through a public URL. You can"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsx)(t.li,{children:(0,o.jsx)(t.a,{href:"../../getting-started/quick-start",children:"run your own node"})}),"\n",(0,o.jsx)(t.li,{children:(0,o.jsx)(t.a,{href:"../nodes",children:"use a public node"})}),"\n"]}),"\n",(0,o.jsx)(t.p,{children:"In this tutorial, we will use public nodes to power the Continue plugin."}),"\n",(0,o.jsxs)(t.table,{children:[(0,o.jsx)(t.thead,{children:(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.th,{children:"Model type"}),(0,o.jsx)(t.th,{children:"API base URL"}),(0,o.jsx)(t.th,{children:"Model name"})]})}),(0,o.jsxs)(t.tbody,{children:[(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:"Chat"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.a,{href:"https://llama8b.gaia.domains/v1",children:"https://llama8b.gaia.domains/v1"})}),(0,o.jsx)(t.td,{children:"llama"})]}),(0,o.jsxs)(t.tr,{children:[(0,o.jsx)(t.td,{children:"Embedding"}),(0,o.jsx)(t.td,{children:(0,o.jsx)(t.a,{href:"https://llama8b.gaia.domains/v1",children:"https://llama8b.gaia.domains/v1"})}),(0,o.jsx)(t.td,{children:"nomic"})]})]})]}),"\n",(0,o.jsx)(t.h2,{id:"start-a-flowiseai-server",children:"Start a FlowiseAI server"}),"\n",(0,o.jsxs)(t.p,{children:["Follow ",(0,o.jsx)(t.a,{href:"https://docs.flowiseai.com/getting-started",children:"the FlowiseAI guide"})," to install Flowise locally"]}),"\n",(0,o.jsx)(t.pre,{children:(0,o.jsx)(t.code,{children:"npm install -g flowise\nnpx flowise start\n"})}),"\n",(0,o.jsxs)(t.p,{children:["After running successfully, you can open ",(0,o.jsx)(t.a,{href:"http://localhost:3000",children:"http://localhost:3000"})," to check out the Flowise AI tool."]}),"\n",(0,o.jsx)(t.h2,{id:"build-a-documents-qna-chatbot",children:"Build a documents QnA chatbot"}),"\n",(0,o.jsx)(t.p,{children:"FlowiseAI allows you to visually set up all the workflow components for an AI agent. If you're new to FlowiseAI, it's recommended to use a template quick start. In fact, there are lots of templates around OpenAI in the Flowise marketplace. All we need to do is to replace the ChatOpenAI component with the ChatLocalAI component."}),"\n",(0,o.jsxs)(t.p,{children:["Let's take the ",(0,o.jsx)(t.strong,{children:"Flowise Docs QnA"})," as an example. You can build a QnA chatbot based on your documents. In this example, we would like to chat with a set of documents in a GitHub repo. The default template was built with OpenAI and we will now change it to use an open-source LLM on a Gaia node."]}),"\n",(0,o.jsxs)(t.h3,{id:"get-the-flowise-docs-qna-template",children:["Get the ",(0,o.jsx)(t.strong,{children:"Flowise Docs QnA"})," template"]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(4560).A+"",width:"2936",height:"1182"})}),"\n",(0,o.jsxs)(t.p,{children:["Click on Marketplaces on the left tab to browse all the templates. The template ",(0,o.jsx)(t.strong,{children:"Flowise Docs QnA"})," we will use is the first one."]}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(8379).A+"",width:"2926",height:"1542"})}),"\n",(0,o.jsx)(t.p,{children:"Then, click on Use this template button on the left top corner to open the visual editor."}),"\n",(0,o.jsx)(t.h3,{id:"connect-the-chat-model-api",children:"Connect the chat model API"}),"\n",(0,o.jsx)(t.p,{children:"You will need to delete the ChatOpenAI component and click the + button to search ChatLocalAI, and then drag the ChatLocalAI to the screen."}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(7874).A+"",width:"1751",height:"856"})}),"\n",(0,o.jsx)(t.p,{children:"Then, you will need to input"}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:["the Gaia node base URL ",(0,o.jsx)(t.code,{children:"https://llama8b.gaia.domains/v1"})]}),"\n",(0,o.jsxs)(t.li,{children:["the model name ",(0,o.jsx)(t.code,{children:"llama"})]}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["Next, connect the ChatLocalAI component with the field ",(0,o.jsx)(t.code,{children:"Chat model"})," in the ",(0,o.jsx)(t.strong,{children:"Conversational Retrieval QA Chain"})," component."]}),"\n",(0,o.jsx)(t.h3,{id:"connect-the-embedding-model-api",children:"Connect the embedding model API"}),"\n",(0,o.jsxs)(t.p,{children:["The default template uses the OpenAI Embeddings component to create embeddings for your documents. We need to replace the ",(0,o.jsx)(t.strong,{children:"OpenAI Embeddings"})," component with the ",(0,o.jsx)(t.strong,{children:"LocalAI Embeddings"})," component."]}),"\n",(0,o.jsxs)(t.ul,{children:["\n",(0,o.jsxs)(t.li,{children:["Use the Gaia node base URL ",(0,o.jsx)(t.code,{children:"https://llama8b.gaia.domains/v1"})," in the Base Path field."]}),"\n",(0,o.jsxs)(t.li,{children:["Input the model name ",(0,o.jsx)(t.code,{children:"nomic-embed-text-v1.5.f16"})," in the Model Name field."]}),"\n"]}),"\n",(0,o.jsxs)(t.p,{children:["Next, connect the ",(0,o.jsx)(t.strong,{children:"LocalAI Embeddings"})," component with the field ",(0,o.jsx)(t.code,{children:"embedding"})," in the ",(0,o.jsx)(t.strong,{children:"In-Memory Vector Store"})," component."]}),"\n",(0,o.jsx)(t.h3,{id:"set-up-your-documents",children:"Set up your documents"}),"\n",(0,o.jsxs)(t.p,{children:["Then, let's go through the GitHub component to connect the chat application to our documents on GitHub. You will need to put your docs GitHub link into the ",(0,o.jsx)(t.strong,{children:"Repo Link"})," field. For example, you can put Gaia's docs link: ",(0,o.jsx)(t.code,{children:"https://github.com/GaiaNet-AI/docs/tree/main/docs"}),"."]}),"\n",(0,o.jsx)(t.h2,{id:"give-it-a-try",children:"Give it a try"}),"\n",(0,o.jsx)(t.p,{children:'You can send a question like "How to install a Gaia node" after saving the current chatflow.'}),"\n",(0,o.jsx)(t.p,{children:(0,o.jsx)(t.img,{src:n(9597).A+"",width:"1739",height:"866"})}),"\n",(0,o.jsx)(t.p,{children:"You will get the answer based on the Gaia docs, which are more accurate."}),"\n",(0,o.jsx)(t.h2,{id:"more-examples",children:"More examples"}),"\n",(0,o.jsxs)(t.p,{children:["There are lots of examples on the Flowise marketplace. To build a Flowise agent based on Gaia, simply replace the ",(0,o.jsx)(t.strong,{children:"Chat OpenAI"})," and ",(0,o.jsx)(t.strong,{children:"OpenAI Embeddings"})," component with the Gaia base URL."]})]})}function h(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,o.jsx)(t,{...e,children:(0,o.jsx)(r,{...e})}):r(e)}},4560:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/flowise-01-38ce1dc6e85edf44ce942f3c032751bc.png"},8379:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/flowise-02-5e4c3abe45028dea057cadc04cae301b.png"},7874:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/flowise-03-00ebd2de39ebd00533f63659e11b1e48.png"},9597:(e,t,n)=>{n.d(t,{A:()=>s});const s=n.p+"assets/images/flowise-04-7ee98ecd7039fbf54776e2300c1e9ca9.png"},8453:(e,t,n)=>{n.d(t,{R:()=>l,x:()=>a});var s=n(6540);const o={},i=s.createContext(o);function l(e){const t=s.useContext(i);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function a(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:l(e.components),s.createElement(i.Provider,{value:t},e.children)}}}]);